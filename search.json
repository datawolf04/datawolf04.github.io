[
  {
    "objectID": "posts/olympic240805/olympicMedalData.html",
    "href": "posts/olympic240805/olympicMedalData.html",
    "title": "Olympic countries: Fun facts and visualizations",
    "section": "",
    "text": "This week we’re exploring Olympics data!\nThe data this week comes from the RGriffin Kaggle dataset: 120 years of Olympic history: athletes and results, basic bio data on athletes and medal results from Athens 1896 to Rio 2016.\nlibrary(tidyverse)\nlibrary(ggtext)\nlibrary(showtext)\nlibrary(janitor)\nlibrary(ggdist)\nlibrary(ggrepel)\nlibrary(scales)\nlibrary(paletteer)\nlibrary(gt)\n\n\nload('olympicMedalResults.RData')"
  },
  {
    "objectID": "posts/olympic240805/olympicMedalData.html#data-in-this-dataset",
    "href": "posts/olympic240805/olympicMedalData.html#data-in-this-dataset",
    "title": "Olympic countries: Fun facts and visualizations",
    "section": "Data in this dataset:",
    "text": "Data in this dataset:\nFirst, I am planning on analyzing the summer and winter olympics separately. Furthermore, it occurs to me that the year in this dataset should be treated as a factor variable, rather than a numeric variable. This will help if (for example) the olympics were skipped or postponed, and it will definitely help when the winter games were shifted by 2 years so that the intervals between games are uniform.\n\ncountryParticipation &lt;- olympics |&gt; count(noc) |&gt;\n  arrange(desc(n)) \n\nMy plan is to plot out participation, medal count, and gold medal count by country NOC region. The reason for this due to the fact that there are an obnoxious number of “teams” (1184) already in this dataset. Also, I don’t think that we want to track the results of “Osborne Swimming Club, Manchester” or “Phalainis ton Thorichtou ‘Psara’-3” on the same level as Spain, China, Brazil, USA, etc. As it stands, there are plenty of countries to keep track of! As it is, there are 230 national olympic committeees. For fun, let’s look at the least frequent participants.\n\n\n\n\n\n\n\n\n\n\n\n\nOlympic participant breakdown\n\n\n10 lowest participating countries\n\n\nCountry code\nParticipant #\n\n\n\n\nYAR\n11\n\n\nBRU\n10\n\n\nTLS\n9\n\n\nKOS\n8\n\n\nTUV\n7\n\n\nYMD\n5\n\n\nSSD\n3\n\n\nNBO\n2\n\n\nUNK\n2\n\n\nNFL\n1\n\n\n\n#TidyTuesday • Source: RGriffin Kaggle dataset\n\n\n\n\n\n\n\n\n\nAside: Ummm…\nWhat is NFL and who is the lone participant from there?\n\nolympics |&gt; filter(noc==\"NFL\") |&gt; glimpse()\n\nRows: 1\nColumns: 15\n$ id     &lt;dbl&gt; 36547\n$ name   &lt;chr&gt; \"Robert Arthur \\\"Bob\\\" Fowler\"\n$ sex    &lt;chr&gt; \"M\"\n$ age    &lt;dbl&gt; 21\n$ height &lt;dbl&gt; 170\n$ weight &lt;dbl&gt; 57\n$ team   &lt;chr&gt; \"Newfoundland\"\n$ noc    &lt;chr&gt; \"NFL\"\n$ games  &lt;chr&gt; \"1904 Summer\"\n$ year   &lt;dbl&gt; 1904\n$ season &lt;chr&gt; \"Summer\"\n$ city   &lt;chr&gt; \"St. Louis\"\n$ sport  &lt;chr&gt; \"Athletics\"\n$ event  &lt;chr&gt; \"Athletics Men's Marathon\"\n$ medal  &lt;chr&gt; NA\n\n\nOk, wait a minute. So the Canadians don’t want to accept this guy? Was Newfoundland it’s own country back then?\n(Feverish googling occurs)\nWell, I’ll be darned, it was! According to Wikipedia:\n\nUntil 1949, the Dominion of Newfoundland was a separate dominion in the British Empire. In 1933, the House of Assembly of the self-governing dominion voted to dissolve itself and to hand over administration of Newfoundland and Labrador to the British-appointed Commission of Government. This followed the suffering caused by the Great Depression and Newfoundland’s participation in the First World War. On March 31, 1949, it became the 10th and most recent province to join the Canadian Confederation as “Newfoundland”. On December 6, 2001, the Constitution of Canada was amended to change the province’s name from “Newfoundland” to “Newfoundland and Labrador”.\n\nHuh…I learn something new every day! And here I thought it was because most Canadians think (insert Newfie joke here)."
  },
  {
    "objectID": "posts/olympic240805/olympicMedalData.html#back-to-the-show",
    "href": "posts/olympic240805/olympicMedalData.html#back-to-the-show",
    "title": "Olympic countries: Fun facts and visualizations",
    "section": "Back to the show",
    "text": "Back to the show\nI think that I should create a function that sorts the participation data (and later, the medalist data) by country and year. Also, since 230 lines would make the graph look like messy spaghetti, I think it would be best to limit the results to the top 10 countries by the metric being plotted (participation, number medalists, number gold medalists).\n\ncountByCountryYearSzn = function(dat,top=TRUE){\n  cbcys &lt;- dat |&gt; group_by(across(all_of(c(\"season\",\"noc\",\"year\")))) |&gt;\n      summarize(\n        pcount = n()\n      ) |&gt;\n    mutate(\n      cumCount = cumsum(pcount)\n    )\n  \n  countryTotal &lt;- dat |&gt; count(noc) |&gt;\n    arrange(desc(n))\n  \n  nC = nrow(countryTotal)\n  \n  if(top){\n    cKeep = countryTotal[1:10, ]\n  }else{\n    cKeep = countryTotal[(nC-10):nC, ]\n  }\n  \n  out &lt;- cbcys |&gt; inner_join(cKeep,join_by(noc))\n  \n  out$noc = factor(out$noc, levels = cKeep$noc)\n\n  return(out)\n}\n\nNow, let’s make a graph of olympic participation:\n\npart = countByCountryYearSzn(olympics,top=TRUE)\n\n`summarise()` has grouped output by 'season', 'noc'. You can override using the\n`.groups` argument.\n\nggplot(part, aes(x=year, y=cumCount, color=noc)) +\n  geom_step() + facet_wrap(~ season, ncol=1, scales=\"free_y\") + \n  theme_simple() + theme(\n    plot.background = element_rect(fill=grn,color=grn),\n    panel.background = element_rect(fill=ltGrn,color=ltGrn),\n    legend.key = element_rect(fill=ltGrn,color=ltGrn),\n    legend.background = element_rect(fill=ltGrn,color=ltGrn)\n  ) +\n  labs(\n    title = \"Olympic participation by country (top 10)\",\n    x = \"Year of Olympic Games\",\n    y = \"Cumulative participant count\",\n    caption = caption_text,\n    color = \"Nation\"\n  ) +\n  scale_color_paletteer_d(col_pal_dis_long)\n\n\n\n\n\n\n\n\nThe medal breakdown\n\nolyMedal &lt;- olympics |&gt; filter(!is.na(medal))\n\nmedalists = countByCountryYearSzn(olyMedal,top=TRUE)\n\n`summarise()` has grouped output by 'season', 'noc'. You can override using the\n`.groups` argument.\n\nggplot(medalists, aes(x=year,y=cumCount,color=noc)) +\n  geom_step() + facet_wrap(~ season, ncol=1, scales=\"free_y\") + \n  theme_simple() + theme(\n    plot.background = element_rect(fill=silver,color=silver),\n    panel.background = element_rect(fill=ltSilver,color=ltSilver),\n    legend.key = element_rect(fill=ltSilver,color=ltSilver),\n    legend.background = element_rect(fill=ltSilver,color=ltSilver)\n  ) +\n  labs(\n    title=\"Olympic medalists by country (top 10)\",\n    x = \"Year of Olympic Games\",\n    y = \"Cumulative medal count\",\n    caption = caption_text,\n    color = \"Nation\"\n  ) +\n  scale_color_paletteer_d(col_pal_dis_long)\n\n\n\n\n\n\n\n\nI will note that URS is the Soviet Union, and RUS is Russia. Clearly that country’s 20th century history means that it is not treated as continuous by the Olympic Federation. It reminds me of when I was a kid watching Where in the World is Carmen Sandiego and all of a sudden there were new countries on the European maps. &lt;/nostalgia trip&gt;\nBut you can totally see the rivalry fueled by the Cold War when you look at the “slope” of the summer olympic medal accumulation graph and compare the Soviets (and later, the Russians) to the Americans.\n\nolyGold &lt;- olympics |&gt; filter(medal==\"Gold\")\n\ngoldMetals = countByCountryYearSzn(olyGold,top=TRUE)\n\n`summarise()` has grouped output by 'season', 'noc'. You can override using the\n`.groups` argument.\n\nggplot(goldMetals, aes(x=year,y=cumCount,color=noc)) +\n  geom_step() + facet_wrap(~ season, ncol = 1, scales=\"free_y\") + \n  theme_simple() + theme(\n    plot.background = element_rect(fill=gold,color=gold),\n    panel.background = element_rect(fill=ltGold,color=ltGold),\n    legend.key = element_rect(fill=ltGold,color=ltGold),\n    legend.background = element_rect(fill=ltGold,color=ltGold)\n  ) +\n  labs(\n    title=\"Olympic Golds by country (top 10)\",\n    x = \"Year of Olympic Games\",\n    y = \"Cumulative gold metal count\",\n    caption = caption_text,\n    color = \"Nation\"\n  ) +\n  scale_color_paletteer_d(col_pal_dis_long)"
  },
  {
    "objectID": "posts/summerMovies/summerMovies.html",
    "href": "posts/summerMovies/summerMovies.html",
    "title": "Summer Movies",
    "section": "",
    "text": "This week we’re exploring “summer” movies: movies with summer in their title!\nThe data this week comes from the Internet Movie Database.\nlibrary(tidyverse)\nlibrary(ggtext)\nlibrary(showtext)\nlibrary(janitor)\nlibrary(ggdist)\nlibrary(ggrepel)\nlibrary(scales)\nlibrary(paletteer)\n\nload('summerMovie.RData')"
  },
  {
    "objectID": "posts/summerMovies/summerMovies.html#popularity-of-movie-by-year",
    "href": "posts/summerMovies/summerMovies.html#popularity-of-movie-by-year",
    "title": "Summer Movies",
    "section": "Popularity of movie by year",
    "text": "Popularity of movie by year\nIn some sense how well-known or popular a movie is should depend on the year. I’m guessing that very old movies may not have as many votes in the IMDB system. This could also bias the ratings\n\nggplot(summer_movies, aes(x=year,y=num_votes)) +\n  geom_point(color=oneCol) + \n  labs(\n    x = \"Year movie released\",\n    y = \"Number of ratings\",\n    caption = caption_text\n  ) + theme_simple()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nI can definitely see that there is a volume bias towards newer movies. Let’s explore if this shows up in the ratings.\n\nggplot(summer_movies, aes(x=num_votes, y=average_rating, color=year)) +\n  geom_point() + \n  scale_x_log10(breaks = trans_breaks(\"log10\", function(x) 10^x),\n                labels = trans_format(\"log10\", math_format(10^.x))) +\n  scale_y_continuous(limits = c(0,10)) + \n  scale_color_paletteer_c(col_pal_cont) +\n  labs(\n    x = \"Number of ratings\",\n    y = \"Average rating\",\n    color = \"Year\",\n    caption = caption_text\n  ) + theme_simple()\n\n\n\n\n\n\n\n\nI’d say that there are no truly universally bad summer movies (for example with everyone scoring it a 0 or 1 out of 10). Despite the recency bias in the rating volume, it would seem that movies can be rated poorly or highly regardless of the year the movie was released. It also seems like there is a “reversion to the mean” effect for movies that have more votes, although this could simply be the result of sparse data. By “reversion to the mean” I am referring to the vaguely triangular shape of the blob of points, suggesting that as a movie is rated more and more, the diversity of opinion forces the mean rating to tend away from extreme values."
  },
  {
    "objectID": "posts/summerMovies/summerMovies.html#re-imagining-other-work",
    "href": "posts/summerMovies/summerMovies.html#re-imagining-other-work",
    "title": "Summer Movies",
    "section": "Re-imagining other work",
    "text": "Re-imagining other work\nAs I’m doing this a bit late in the game, I can take advantage of the work some others have done. I saw this plot, and thought it would be good to replicate here, with a subtle twist.\n\nRather than plotting mean values for each genre, I thought I’d make a box plot instead of plotting the average rating. So I will tidy up the data. Furthermore, since I’m creating a box plot, I’m going to remove genres with fewer than \\(N=5\\) ratings.\n\nglobalMedian = median(summer_movies$average_rating, na.rm = TRUE)\ngDat &lt;- summer_movies |&gt; separate_longer_delim(cols = genres, delim = \",\") |&gt;\n  group_by(genres) \n\nnewGenre &lt;-  gDat |&gt;\n  summarise(\n    count = n(),\n    rating = median(average_rating, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\ndata4plot = full_join(newGenre,gDat,by=\"genres\") |&gt;\n  mutate(\n      genre_count = str_glue(\"{genres} ({count})\"),\n      genre_count = fct_reorder(genre_count, rating, .desc = FALSE),\n      highlight = ifelse(rating &gt;= globalMedian, \"yes\",\"no\")\n      ) |&gt;\n  filter(count&gt;=5)\n\nAnd finally, the plot.\n\nggplot(data4plot, aes(x=average_rating, y=genre_count, fill=highlight)) +\n  geom_vline(\n    xintercept = globalMedian,\n    linewidth = .5,\n    color = 'gray'\n    ) +\n  geom_boxplot() +\n  labs(\n    x = \"Rating\",\n    y = \"Movie Genre (count)\",\n    caption = caption_text\n  ) +\n  scale_x_continuous(breaks = seq(2,10,by=1), limits=c(2,10)) +\n  scale_y_discrete() +\n  scale_fill_paletteer_d(col_pal_dis) +\n  coord_cartesian(clip='off') + theme_catY()"
  },
  {
    "objectID": "posts/summerMovies/summerMovies.html#final-notes",
    "href": "posts/summerMovies/summerMovies.html#final-notes",
    "title": "Summer Movies",
    "section": "Final notes",
    "text": "Final notes\nI just found out about #TidyTuesday, just this week, and I want to participate. So the purpose of this post is mostly to get a blog going, and I hope to update approximately monthly. Now that this post is written, we’ll see if I can get this onto Github Pages. 😄\n[Edit: Phew! That worked!]"
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "Steve's Data Playground",
    "section": "",
    "text": "This is the weblog so I can do some #TidyTuesday activities and play with Quarto.\nGo to the webpage here: datawolf04.github.io"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m a physicist by training, but a Data Scientist by practice. I’ve been coding things in R and Python for several years, and I finally decided that I wanted a place to put my fun projects, organize my thoughts, and do other data science related things. In addition to the places you will find me linked to the bottom, you can find me active with #TidyTuesday and the Data Science Learning Community."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Steve’s Data Playground",
    "section": "",
    "text": "Scraping Weather Data-Proof of concept\n\n\n\n\n\n\nweather\n\n\npython\n\n\nweb-scraping\n\n\n\nScraping weather data near Zebulon, NC\n\n\n\n\n\nAug 8, 2024\n\n\nSteven Wolf\n\n\n\n\n\n\n\n\n\n\n\n\nOlympic countries: Fun facts and visualizations\n\n\n\n\n\n\ntidyTuesday\n\n\nR\n\n\n\nCountries by participation and medal count\n\n\n\n\n\nAug 7, 2024\n\n\nSteven Wolf\n\n\n\n\n\n\n\n\n\n\n\n\nSummer Movies\n\n\n\n\n\n\ntidyTuesday\n\n\nR\n\n\n\nAnalyzing the IMDB for movies with ‘summer’ in the title\n\n\n\n\n\nAug 2, 2024\n\n\nSteven Wolf\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/weatherScrape240808/weatherScrape.html",
    "href": "posts/weatherScrape240808/weatherScrape.html",
    "title": "Scraping Weather Data-Proof of concept",
    "section": "",
    "text": "My friend, Ben Leese, was telling me about his most recent project. He has a passion for going through old naturalist’s notebooks and pulling out data from the depths of that analog mess and bringing it into the digital world. He was talking to me about how weather could impact different bird behaviors. But he only had binary weather data (Yes, it rained/No, it didn’t rain). Furthermore, it was from Raleigh, NC rather than Zebulon, NC. While these places are close on the map, weather is even more local than politics. So I said that I’d try to find some better weather data for him.\nI found this helpful python script for scraping the weather data from Weather Underground, which I will adapt to my purpose.\n\nimport time\nimport sys\n\nimport numpy as np\nimport pandas as pd\nfrom bs4 import BeautifulSoup as BS\nfrom selenium import webdriver\nfrom great_tables import GT\nfrom scrape_wunderground import *\n\nI will scrape weather from the BreakingWind station with code KNCZEBUL74 on 8/1/2024, as I am pretty sure this is the closest station to the desired location.\n\nstation_id = \"KNCZEBUL74\"\ndate_id = \"2024-08-01\"\n\n(\n  GT(scrape_wunderground(station_id,date_id).head(20))\n    .tab_options(\n      column_labels_background_color = \"#3B3A3EFF\",\n  )\n)\n\n\n\n\n\n\n\ntimestamps\nTemperature\nDew Point\nHumidity\nWind Speed\nWind Gust\nPressure\nPrecip. Rate\nPrecip. Accum.\n\n\n\n\n2024-08-01 12:04 AM\n75.0\n72.0\n92.0\n0.0\n0.0\n29.92\n0.0\n0.0\n\n\n2024-08-01 12:09 AM\n75.0\n72.0\n92.0\n0.0\n0.0\n29.92\n0.0\n0.0\n\n\n2024-08-01 12:14 AM\n75.0\n72.0\n92.0\n0.0\n0.0\n29.92\n0.0\n0.0\n\n\n2024-08-01 12:19 AM\n74.8\n72.0\n91.0\n0.0\n0.0\n29.92\n0.0\n0.0\n\n\n2024-08-01 12:24 AM\n74.8\n72.0\n91.0\n0.0\n0.0\n29.93\n0.0\n0.0\n\n\n2024-08-01 12:29 AM\n74.8\n72.0\n91.0\n0.0\n0.0\n29.93\n0.0\n0.0\n\n\n2024-08-01 12:34 AM\n74.7\n72.0\n92.0\n0.0\n0.0\n29.93\n0.0\n0.0\n\n\n2024-08-01 12:39 AM\n74.7\n72.0\n92.0\n0.0\n0.0\n29.93\n0.0\n0.0\n\n\n2024-08-01 12:44 AM\n74.6\n72.0\n92.0\n0.0\n0.0\n29.93\n0.0\n0.0\n\n\n2024-08-01 12:49 AM\n74.5\n72.6\n93.0\n0.0\n0.0\n29.93\n0.0\n0.0\n\n\n2024-08-01 12:54 AM\n74.5\n73.0\n93.0\n0.0\n0.0\n29.93\n0.0\n0.0\n\n\n2024-08-01 12:59 AM\n74.7\n73.0\n93.0\n0.0\n0.0\n29.93\n0.0\n0.0\n\n\n2024-08-01 1:04 AM\n74.7\n73.0\n93.0\n0.0\n0.0\n29.92\n0.0\n0.0\n\n\n2024-08-01 1:09 AM\n74.7\n72.3\n92.0\n0.0\n0.0\n29.92\n0.0\n0.0\n\n\n2024-08-01 1:14 AM\n74.7\n72.2\n92.0\n0.0\n0.0\n29.92\n0.0\n0.0\n\n\n2024-08-01 1:19 AM\n74.6\n72.0\n92.0\n0.0\n0.0\n29.92\n0.0\n0.0\n\n\n2024-08-01 1:24 AM\n74.5\n72.0\n92.0\n0.0\n0.0\n29.92\n0.0\n0.0\n\n\n2024-08-01 1:29 AM\n74.5\n72.0\n92.0\n0.0\n0.0\n29.92\n0.0\n0.0\n\n\n2024-08-01 1:34 AM\n74.5\n72.9\n93.0\n0.0\n0.0\n29.92\n0.0\n0.0\n\n\n2024-08-01 1:39 AM\n74.5\n73.0\n93.0\n0.0\n0.0\n29.92\n0.0\n0.0\n\n\n\n\n\n\n        \n\n\nAnd it works! That being said, I’ll have to find a different weather station because this one seems somewhat new. There is only partial data for 5/29/2024.\n\ndate_id = \"2024-05-29\"\n(\n  GT(scrape_wunderground(station_id,date_id).head(20))\n    .tab_options(\n      column_labels_background_color = \"#3B3A3EFF\",\n  )\n)\n\n\n\n\n\n\n\ntimestamps\nTemperature\nDew Point\nHumidity\nWind Speed\nWind Gust\nPressure\nPrecip. Rate\nPrecip. Accum.\n\n\n\n\n2024-05-29 10:34 PM\n71.2\n51.2\n50.0\n0.2\n0.2\n29.93\n0.0\n0.0\n\n\n2024-05-29 10:39 PM\n71.7\n53.9\n54.0\n1.4\n9.0\n29.94\n0.1\n0.1\n\n\n2024-05-29 10:44 PM\n73.1\n55.1\n53.0\n0.8\n10.0\n29.94\n0.1\n0.1\n\n\n2024-05-29 10:49 PM\n72.8\n54.9\n53.0\n0.0\n10.0\n29.94\n0.1\n0.1\n\n\n2024-05-29 10:54 PM\n72.4\n53.5\n52.0\n0.0\n10.0\n29.94\n0.1\n0.1\n\n\n2024-05-29 10:59 PM\n72.2\n53.0\n52.0\n0.0\n10.0\n29.94\n0.1\n0.1\n\n\n2024-05-29 11:04 PM\n72.1\n53.0\n52.0\n0.0\n10.0\n29.95\n0.1\n0.1\n\n\n2024-05-29 11:09 PM\n72.0\n53.0\n52.0\n0.0\n10.0\n29.95\n0.1\n0.1\n\n\n2024-05-29 11:14 PM\n71.9\n52.1\n51.0\n0.0\n10.0\n29.95\n0.1\n0.1\n\n\n2024-05-29 11:19 PM\n71.8\n51.8\n51.0\n0.0\n10.0\n29.95\n0.1\n0.1\n\n\n2024-05-29 11:24 PM\n71.6\n51.6\n51.0\n0.0\n10.0\n29.95\n0.1\n0.1\n\n\n2024-05-29 11:29 PM\n71.6\n51.0\n50.0\n0.0\n10.0\n29.95\n0.1\n0.1\n\n\n2024-05-29 11:34 PM\n71.4\n51.0\n49.0\n0.0\n10.0\n29.95\n0.1\n0.1\n\n\n2024-05-29 11:39 PM\n71.3\n51.0\n49.0\n0.0\n8.0\n29.95\n0.1\n0.1\n\n\n2024-05-29 11:44 PM\n71.2\n50.1\n48.0\n0.0\n2.0\n29.95\n0.0\n0.1\n\n\n2024-05-29 11:49 PM\n71.1\n50.0\n47.0\n0.0\n1.3\n29.95\n0.0\n0.1\n\n\n2024-05-29 11:54 PM\n71.1\n50.0\n47.0\n0.0\n0.0\n29.94\n0.0\n0.1\n\n\n2024-05-29 11:59 PM\n70.9\n50.0\n47.0\n0.0\n0.0\n29.94\n0.0\n0.1\n\n\n\n\n\n\n        \n\n\nAnd 5/28/2024 has no data.\n\ndate_id = \"2024-05-28\"\n(\n  GT(scrape_wunderground(station_id,date_id).head(20))\n    .tab_options(\n      column_labels_background_color = \"#3B3A3EFF\",\n  )\n)\n\n\n\n\n\n\n\ntimestamps\nTemperature\nDew Point\nHumidity\nWind Speed\nWind Gust\nPressure\nPrecip. Rate\nPrecip. Accum.\n\n\n\n\n\n\n\n\n        \n\n\nI will have to find a different nearby weather station for this purpose of finding Ben some weather data for the time period he is interested in (mid 1970s). And, once I succeed at that, I will have to aggregate the 5-minute data to daily data. But once that’s done, my friend should have more than enough weather data to help him with his model."
  }
]